# 소프트웨어는 정말로 점점 안 좋아지고 있을까?

이전 아티클에 "The Hardware Lottery"라는 논문을 정리한 적이 있었죠. 그중에서도 가장 기억에 남는 부분은 "Low-Hanging Fruit”에 대한 언급이었는데요, 논문에서는 "과거에 하드웨어의 발전 덕분에 쉽게 얻었던 성능 향상이 이제는 더 어려워졌고, 오히려 현재는 소프트웨어 최적화를 통해 쉽게 성과를 낼 수 있는 영역이 많이 남아 있다”고 주장했습니다. 이는 얼핏 보면 "현대 소프트웨어가 과거보다 오히려 퇴보한 게 아닌가?"라는 생각이 들게 합니다. 과연 그런 걸까요? 최적화 업무를 메인으로 하는 입장에서는 공감 가는 부분도 있지만, 한편으로는 실제로 그렇게 단정 지을 수 있는지 의문이 들었습니다. 그래서 이번 기회에 이 문제를 좀 더 명확히 짚어보고 싶었습니다.

분명 오늘날의 컴퓨터는 수십 년 전의 컴퓨터에 비해 수천, 수만 배 더 빠른건 사실입니다. 하지만 사람들의 체감은 다르죠. 오히려 많은 사람들이 최신 앱과 프로그램들이 꼭 더 빠르다고 느끼지 않고 있습니다. 특히 게임 업계에서는 흔히 말하는 '발적화'로 인해 커뮤니티에서 욕을 자주 먹고 있죠. 저는 실제로 최근 발매한 몬스터헌터 와일즈를 사서 해볼까 싶었지만, 스팀덱에서 플레이하기 힘들다고 해서 누워서 게임을 하는 걸 좋아하는 저에게는 구매를 포기할 수 밖에 없었습니다.

게임 뿐만 아닌 단순 프로그램에서도 이런 현상이 있는데요. 2000년대 초반의 OS가 설치된 오래된 PC의 소프트웨어가 최신 OS 및 소프트웨어를 돌리는 신형 컴퓨터보다 오히려 더 반응 속도가 빠른 경우도 있습니다. 이는 과거의 향수가 아닌 실제로 실험으로 나온 결과죠.

왜 이런 일이 발생하는 걸까요? 혹시 흔히 말하는 "MZ 개발자”들이 과거 개발자보다 실력이 떨어져서 그런 걸까요? 사실 이 문제는 개인의 역량보다 개발자의 전략적 선택, 기업의 비즈니스적 타협, 그리고 시대적 우선순위가 복합적으로 얽혀 있는 현상일지도 모릅니다.

아래에서는 소프트웨어 효율성이 지금까지 어떻게 변화해왔는지 살펴보겠습니다. 과거와 현재의 성능을 직접 비교하면서, 소프트웨어가 정말로 퇴보한 것인지 아니면 시대적 우선순위가 달라진 것인지 확인해볼 것입니다. 더불어 개발자들이 성능 대신 다른 가치를 선택하는 이유와 비효율성이 용인되는 배경을 알아보고, 미래 기술이 이 문제를 어떻게 해결할 수 있을지도 살펴보겠습니다.

## 목차

1. 과거의 프로그램이 정말 더 빨랐을까?
2. 과연 소프트웨어가 비효율적이게 된 것일까?
4. 소프트웨어 효율성을 높이는 미래 기술들
5. 결론

## 과거의 프로그램이 정말 더 빨랐을까?

오늘날의 소프트웨어가 정말 느려진 걸까요, 아니면 단순한 향수일까요? 실제로 과거 소프트웨어가 최신 소프트웨어보다 기본적인 작업에서 더 빠르게 반응하는 사례는 많습니다. 이는 **옛날 하드웨어가 강력해서가 아니라, 단순히 소프트웨어가 더 적은 일**을 했기 때문입니다.

한 [기술 블로거](https://jmmv.dev/2023/06/fast-machines-slow-machines.html#:~:text=To%20summarize%2C%20the%20Twitter%20thread,agree%20we%20have%20a%20problem)는 2000년대 초반의 오래된 PC(Windows NT 3.51)와 최신 노트북(Windows 11)을 비교한 영상을 올렸습니다. 메모장이나 그림판처럼 간단한 프로그램을 실행해보니 20년 된 컴퓨터가 최신 고사양 컴퓨터보다 훨씬 빠르게 앱을 열었습니다. 600MHz CPU에 128MB RAM을 가진 오래된 PC가 몇 GHz CPU와 32GB RAM을 가진 최신 기기보다 빠르게 작동하는 모습은 충격을 불러일으켰습니다.

위의 시각적인 비교 이외에 정교한 수치적 비교도 있습니다. 개발자 댄 루(Dan Luu)는 [과거 40년간의 컴퓨터 입력 지연 시간을 측정해 놀라운 결과](https://danluu.com/input-lag/)를 보였습니다. 1983년 Apple IIe는 입력 지연이 약 30ms였던 반면, 2014년 맥북 프로는 약 100ms, 최신 Windows PC는 무려 200ms였습니다. **과거 기기가 최신 컴퓨터보다 반응성이 뛰어난 셈**이죠.

왜 이런 차이가 날까요? 과거 컴퓨터는 하나의 프로그램만 실행했고, 백그라운드 작업도 적었으며, 제한된 자원에 맞춰 철저히 최적화되어 있었습니다. 반면 현대 컴퓨터는 입력 신호가 수많은 계층(USB 드라이버, 운영체제 이벤트 큐, 그래픽 처리 등)을 통과하면서 복잡성과 지연이 증가합니다.

댄 루의 연구는 또 하나 흥미로운 점을 지적합니다. **입력 지연을 줄이기 위한 현대적인 노력조차도 종종 새로운 복잡성을 더하는 방향으로 진행된다고 주장합니다.** 예를 들어, 과거의 빠른 반응성을 되찾기 위해 GPU 가속 합성, 예측 입력 처리 등 추가적인 시스템이 도입되곤 합니다. 아이러니하게도, 느려진 복잡한 시스템을 빠르게 만들기 위해 또 다른 복잡한 시스템을 얹는 셈이죠. 예를 들어 백그라운드에서 미리 데이터를 로드하거나 캐시하여 지연을 감추는 식입니다. 사용자 경험은 향상될 수 있지만, 과거에 비해 훨씬 많은 일이 "보이지 않는 곳"에서 벌어지고 있다는 점을 보여줍니다.

물론, 과거와 현재의 비교가 완전히 공정하진 않습니다. 요즘 앱은 단순히 텍스트 버퍼만 열지 않고, **네트워크 연결 확인, 플러그인 로드, 클라우드 자동저장 등 더 많은 일을 수행**합니다. 기능이 많아진 만큼 무거워진 것이죠.

하지만 모든 현대 소프트웨어가 느린 건 아닙니다. 일부 개발자들은 이 문제를 인식하고 가벼운 소프트웨어를 다시 추구하고 있습니다. 특히 스마트폰처럼 하드웨어가 제한된 환경에서는 백그라운드 작업을 엄격히 줄이고, UI와 입력 처리 흐름을 단순화하여 매우 빠른 반응성을 구현하고 있습니다. 예를 들어 최신 iPad Pro는 Apple IIe 수준인 30ms의 입력 지연을 보여줍니다. 데스크톱 환경에서도 리눅스나 경량 프로젝트들은 최소한의 작업으로 빠른 반응을 추구합니다.

## 과연 소프트웨어가 비효율적이게 된 것일까?

위 사례처럼 하드웨어 성능이 좋아지면서 다양한 기능이 들어가고 있으며 소프트웨어가 점점 무거워지고 있습니다. 기술 업계에서는 소프트웨어가 하드웨어 성능을 모두 소모한다는 농담이 자주 나옵니다. 1990년대엔 ["앤디가 주면 빌이 가져간다"](https://en.wikipedia.org/wiki/Andy_and_Bill%27s_law)라는 유명한 우스갯소리도 있었죠. 인텔의 앤디 그로브가 더 빠른 CPU를 내놓으면, 마이크로소프트의 빌 게이츠가 곧바로 그 성능을 모두 소모하는 소프트웨어를 출시한다는 이야기입니다. 즉, 하드웨어가 아무리 발전해도 그 자원을 전부 활용하는 무거운 소프트웨어가 바로 뒤따라 나온다는 것이죠.

이를 풍자한 ["위르트의 법칙(Wirth's Law)"](https://en.wikipedia.org/wiki/Wirth%27s_law)이라는 말도 있습니다. 이 법칙에 따르면, *"소프트웨어는 하드웨어가 빨라지는 속도보다 더 빠르게 느려진다"*고 합니다. 결국 시간이 흐를수록 소프트웨어는 더 많은 자원을 요구하고, 하드웨어 발전의 이점이 상쇄되는 일이 반복된다는 의미죠. (지금까지의 사례를 보면 어느 정도 일리가 있어 보입니다.)

하지만 이를 너무 부정적으로만 볼 필요는 없습니다. 소프트웨어가 과거에 비해 느려졌다고 단순히 '퇴보'로 평가할 수는 없습니다. 우리가 소프트웨어의 속도를 약간 희생하면서 얻은 이점들이 훨씬 크기 때문이죠. 위 사례처럼 다양한 기능의 추가뿐만 아니라 저는 특히 **개발과 유지보수의 용이함**을 가장 먼저 강조하고 싶습니다.

오늘날 대부분의 개발자들은 **객체 지향 프로그래밍(OOP)**을 당연하게 받아들입니다. Python, Java, C++ 같은 언어들은 모두 객체 지향 프로그래밍 방식을 기본으로 사용하며, 저 또한 Python으로 개발할 때 프로젝트의 규모가 커지면 대부분 객체 지향적 구조를 적용합니다. 하지만 사실 이 객체 지향 프로그래밍은 구조적으로 어느 정도 성능을 희생할 수밖에 없는 방식이라는 걸 알고 계실 겁니다.

객체 지향의 창시자 Alan Kay가 객체 지향 개념을 만든 이유는 성능이 아니라 **인간 중심적인 철학** 때문이었습니다. 그는 특히 교육을 중요하게 여겼고, 아이들을 위한 교육용 컴퓨터인 Dynabook를 구상하면서 최초의 객체 지향 언어인 Smalltalk을 만들었습니다. 그는 Smalltalk를 통해 아이들이 더 유연하게 생각하고 창의적인 방식으로 문제를 해결하기를 원했습니다. 그래서 Smalltalk는 객체들이 서로 메시지를 주고받는 방식으로 설계되었죠.

그러나 이러한 장점에도 불구하고 Smalltalk는 당시 널리 쓰이던 C에 비하면 성능이 상당히 느리고, 메모리 사용량도 더 많았습니다. 이는 주로 객체 지향의 런타임 다형성(dynamic dispatch), 간접 참조(indirect reference), 가상 함수 호출(virtual function call) 등으로 인한 런타임 오버헤드 때문이었습니다. 물론 애초에 Smalltalk가 성능을 목표로 만들어진 언어는 아니었지만, 이 점을 감안해도 느린 건 사실이었죠.

그렇다면 성능을 위해 객체 지향을 버리고 모든 소프트웨어를 C나 Rust처럼 저수준 언어로 작성하면 되는 걸까요? 특수한 경우를 제외하면 아마 오늘날의 현실에서 그런 걸 주장하면 동료들에게 이상한 사람 취급을 받거나 심지어 해고를 당할 수도 있겠죠.

앞에서 이야기했듯이 객체 지향 프로그래밍은 인간 중심적인 철학에서 비롯되었고, 현실 세계와 매우 유사한 방식으로 구조화된다는 점에서 코드를 쉽게 이해하고 설계할 수 있게 해줍니다. 결국 핵심은 **"개발이 쉽고 유지보수가 용이하다"**는 것입니다. 오늘날의 하드웨어는 과거보다 수천 수만 배나 빠르고 강력해졌기 때문에, 설령 객체 지향 코드가 절차적 코드에 비해 몇 배에서 많게는 수십 배 느리다고 하더라도 이미 그 차이는 실질적으로 큰 의미가 없게 되었습니다. **현대의 소프트웨어는 어느 정도의 성능을 기꺼이 희생하고라도, 더 쉽고 빠르게 개발하고, 유지보수하기 좋으며, 손쉽게 확장할 수 있는 구조를 갖추는 것**을 선택한 것입니다. 덤으로 코드의 가독성도 훨씬 좋은 편이죠.

"컴퓨팅 자원은 개발자의 시간보다 싸다"는 말이 있죠. 기업은 제품이 최대한 빨리 나오기 위해서 때론 개발자의 시간을 사용하는 것보다 컴퓨팅 자원을 더 가져가는게 기업의 입장에선 더 이득일 수 있습니다. 그리고 비용이 비싸지면 그 때 최적화를 진행하는게 더 비용 효율적이죠.